{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005932,
     "end_time": "2023-02-07T00:59:58.147501",
     "exception": false,
     "start_time": "2023-02-07T00:59:58.141569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBoost Baseline - LB 0.678\n",
    "In this notebook we present a XGBoost baseline. We train GroupKFold models for each of the 18 questions. Our CV score is 0.678. We infer test using one of our KFold models. We can improve our CV and LB by engineering more features for our xgboost and/or trying different models (like other ML models and/or RNN and/or Transformer). Also we can improve our LB by using more KFold models OR training one model using all data (and the hyperparameters that we found from our KFold cross validation).\n",
    "\n",
    "Here I will present an XGBoost baseline. I will train Gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:30:18.763479Z",
     "iopub.status.busy": "2023-02-08T17:30:18.762917Z",
     "iopub.status.idle": "2023-02-08T17:30:20.110141Z",
     "shell.execute_reply": "2023-02-08T17:30:20.109086Z",
     "shell.execute_reply.started": "2023-02-08T17:30:18.763372Z"
    },
    "papermill": {
     "duration": 1.027875,
     "end_time": "2023-02-07T00:59:59.180261",
     "exception": false,
     "start_time": "2023-02-07T00:59:58.152386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004542,
     "end_time": "2023-02-07T00:59:59.189777",
     "exception": false,
     "start_time": "2023-02-07T00:59:59.185235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Train Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:30:20.113952Z",
     "iopub.status.busy": "2023-02-08T17:30:20.113568Z",
     "iopub.status.idle": "2023-02-08T17:31:30.17235Z",
     "shell.execute_reply": "2023-02-08T17:31:30.171344Z",
     "shell.execute_reply.started": "2023-02-08T17:30:20.113921Z"
    },
    "papermill": {
     "duration": 59.284316,
     "end_time": "2023-02-07T01:00:58.478743",
     "exception": false,
     "start_time": "2023-02-07T00:59:59.194427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>3</td>\n",
       "      <td>1147</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gotta run to my meeting!</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>4</td>\n",
       "      <td>1863</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-412.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>381.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can I come, Gramps?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level  page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0   NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0   NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0   NaN   \n",
       "3  20090312431273200      3          1147    person_click  basic      0   NaN   \n",
       "4  20090312431273200      4          1863    person_click  basic      0   NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "1  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "2  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "3  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "4  -412.991405  -159.314686          381.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
       "4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid  fullscreen  hq  music  \\\n",
       "0               tunic.historicalsociety.closet.intro         NaN NaN    NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN    NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN    NaN   \n",
       "3  tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN    NaN   \n",
       "4  tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN    NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  \n",
       "3         0-4  \n",
       "4         0-4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =  pd.read_csv('/Users/erica.stevenson/ML_projects/Predict_Student_Performance/predict-student-performance-from-game-play/train.csv')\n",
    "print( train.shape )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:31:30.17428Z",
     "iopub.status.busy": "2023-02-08T17:31:30.173802Z",
     "iopub.status.idle": "2023-02-08T17:31:30.793235Z",
     "shell.execute_reply": "2023-02-08T17:31:30.792286Z",
     "shell.execute_reply.started": "2023-02-08T17:31:30.174246Z"
    },
    "papermill": {
     "duration": 0.598155,
     "end_time": "2023-02-07T01:00:59.082015",
     "exception": false,
     "start_time": "2023-02-07T01:00:58.48386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>session</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090314121766812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090314363702160_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090314363702160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090314441803444_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090314441803444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct            session  q\n",
       "0  20090312431273200_q1        1  20090312431273200  1\n",
       "1  20090312433251036_q1        0  20090312433251036  1\n",
       "2  20090314121766812_q1        1  20090314121766812  1\n",
       "3  20090314363702160_q1        1  20090314363702160  1\n",
       "4  20090314441803444_q1        1  20090314441803444  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets =  pd.read_csv('/Users/erica.stevenson/ML_projects/Predict_Student_Performance/predict-student-performance-from-game-play/train_labels.csv')\n",
    "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "print( targets.shape )\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005196,
     "end_time": "2023-02-07T01:00:59.092865",
     "exception": false,
     "start_time": "2023-02-07T01:00:59.087669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineer\n",
    "We create basic aggregate features. Try creating more features to boost CV and LB! The idea for EVENTS feature is from [here][1]\n",
    "\n",
    "[1]: https://www.kaggle.com/code/kimtaehun/lightgbm-baseline-with-aggregated-log-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:31:30.795866Z",
     "iopub.status.busy": "2023-02-08T17:31:30.795255Z",
     "iopub.status.idle": "2023-02-08T17:31:30.803239Z",
     "shell.execute_reply": "2023-02-08T17:31:30.802164Z",
     "shell.execute_reply.started": "2023-02-08T17:31:30.795828Z"
    },
    "papermill": {
     "duration": 0.014685,
     "end_time": "2023-02-07T01:00:59.112856",
     "exception": false,
     "start_time": "2023-02-07T01:00:59.098171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATS = ['event_name', 'fqid', 'room_fqid', 'text']\n",
    "NUMS = ['elapsed_time','level','page','room_coor_x', 'room_coor_y', \n",
    "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
    "\n",
    "# https://www.kaggle.com/code/kimtaehun/lightgbm-baseline-with-aggregated-log-data\n",
    "EVENTS = ['navigate_click','person_click','cutscene_click','object_click',\n",
    "          'map_hover','notification_click','map_click','observation_click',\n",
    "          'checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:31:30.80549Z",
     "iopub.status.busy": "2023-02-08T17:31:30.804639Z",
     "iopub.status.idle": "2023-02-08T17:31:30.81666Z",
     "shell.execute_reply": "2023-02-08T17:31:30.815607Z",
     "shell.execute_reply.started": "2023-02-08T17:31:30.805455Z"
    },
    "papermill": {
     "duration": 0.017716,
     "end_time": "2023-02-07T01:00:59.136021",
     "exception": false,
     "start_time": "2023-02-07T01:00:59.118305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(train):\n",
    "    \n",
    "    dfs = []\n",
    "    for c in CATS:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('nunique')\n",
    "        tmp.name = tmp.name + '_nunique'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMS:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('mean')\n",
    "        tmp.name = tmp.name + '_mean'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMS:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)\n",
    "    for c in EVENTS: \n",
    "        train[c] = (train.event_name == c).astype('int8')\n",
    "    for c in EVENTS + ['elapsed_time']:\n",
    "        tmp = train.groupby(['session_id','level_group'])[c].agg('sum')\n",
    "        tmp.name = tmp.name + '_sum'\n",
    "        dfs.append(tmp)\n",
    "    train = train.drop(EVENTS,axis=1)\n",
    "        \n",
    "    df = pd.concat(dfs,axis=1)\n",
    "    df = df.fillna(-1)\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index('session_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:31:30.818517Z",
     "iopub.status.busy": "2023-02-08T17:31:30.818058Z",
     "iopub.status.idle": "2023-02-08T17:32:35.494885Z",
     "shell.execute_reply": "2023-02-08T17:32:35.493981Z",
     "shell.execute_reply.started": "2023-02-08T17:31:30.818484Z"
    },
    "papermill": {
     "duration": 34.516494,
     "end_time": "2023-02-07T01:01:33.658043",
     "exception": false,
     "start_time": "2023-02-07T01:00:59.141549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = feature_engineer(train)\n",
    "print( df.shape )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00565,
     "end_time": "2023-02-07T01:01:33.669525",
     "exception": false,
     "start_time": "2023-02-07T01:01:33.663875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train XGBoost Model\n",
    "We train one model for each of 18 questions. Furthermore, we use data from `level_groups = '0-4'` to train model for questions 1-3, and `level groups '5-12'` to train questions 4 thru 13 and `level groups '13-22'` to train questions 14 thru 18. Because this is the data we get (to predict corresponding questions) from Kaggle's inference API during test inference. We can improve our model by saving a user's previous data from earlier `level_groups` and using that to predict future `level_groups`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:32:35.496867Z",
     "iopub.status.busy": "2023-02-08T17:32:35.496039Z",
     "iopub.status.idle": "2023-02-08T17:32:35.506244Z",
     "shell.execute_reply": "2023-02-08T17:32:35.505151Z",
     "shell.execute_reply.started": "2023-02-08T17:32:35.496833Z"
    },
    "papermill": {
     "duration": 0.014699,
     "end_time": "2023-02-07T01:01:33.689953",
     "exception": false,
     "start_time": "2023-02-07T01:01:33.675254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES = [c for c in df.columns if c != 'level_group']\n",
    "print('We will train with', len(FEATURES) ,'features')\n",
    "ALL_USERS = df.index.unique()\n",
    "print('We will train with', len(ALL_USERS) ,'users info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:32:35.508778Z",
     "iopub.status.busy": "2023-02-08T17:32:35.507917Z",
     "iopub.status.idle": "2023-02-08T17:34:16.960612Z",
     "shell.execute_reply": "2023-02-08T17:34:16.959368Z",
     "shell.execute_reply.started": "2023-02-08T17:32:35.50874Z"
    },
    "papermill": {
     "duration": 69.877213,
     "end_time": "2023-02-07T01:02:43.57299",
     "exception": false,
     "start_time": "2023-02-07T01:01:33.695777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "oof = pd.DataFrame(data=np.zeros((len(ALL_USERS),18)), index=ALL_USERS)\n",
    "models = {}\n",
    "\n",
    "# COMPUTE CV SCORE WITH 5 GROUP K FOLD\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X=df, groups=df.index)):\n",
    "    print('#'*25)\n",
    "    print('### Fold',i+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    xgb_params = {\n",
    "    'objective' : 'binary:logistic',\n",
    "    'eval_metric':'logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'n_estimators': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'tree_method':'hist',\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'use_label_encoder' : False}\n",
    "    \n",
    "    # ITERATE THRU QUESTIONS 1 THRU 18\n",
    "    for t in range(1,19):\n",
    "        \n",
    "        # USE THIS TRAIN DATA WITH THESE QUESTIONS\n",
    "        if t<=3: grp = '0-4'\n",
    "        elif t<=13: grp = '5-12'\n",
    "        elif t<=22: grp = '13-22'\n",
    "            \n",
    "        # TRAIN DATA\n",
    "        train_x = df.iloc[train_index]\n",
    "        train_x = train_x.loc[train_x.level_group == grp]\n",
    "        train_users = train_x.index.values\n",
    "        train_y = targets.loc[targets.q==t].set_index('session').loc[train_users]\n",
    "        \n",
    "        # VALID DATA\n",
    "        valid_x = df.iloc[test_index]\n",
    "        valid_x = valid_x.loc[valid_x.level_group == grp]\n",
    "        valid_users = valid_x.index.values\n",
    "        valid_y = targets.loc[targets.q==t].set_index('session').loc[valid_users]\n",
    "        \n",
    "        # TRAIN MODEL        \n",
    "        clf =  XGBClassifier(**xgb_params)\n",
    "        clf.fit(train_x[FEATURES].astype('float32'), train_y['correct'],\n",
    "                eval_set=[ (valid_x[FEATURES].astype('float32'), valid_y['correct']) ],\n",
    "                verbose=0)\n",
    "        print(f'{t}({clf.best_ntree_limit}), ',end='')\n",
    "        \n",
    "        # SAVE MODEL, PREDICT VALID OOF\n",
    "        models[f'{grp}_{t}'] = clf\n",
    "        oof.loc[valid_users, t-1] = clf.predict_proba(valid_x[FEATURES].astype('float32'))[:,1]\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011241,
     "end_time": "2023-02-07T01:02:43.59638",
     "exception": false,
     "start_time": "2023-02-07T01:02:43.585139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Compute CV Score\n",
    "We need to convert prediction probabilities into `1s` and `0s`. The competition metric is F1 Score which is the harmonic mean of precision and recall. Let's find the optimal threshold for `p > threshold` when to predict `1` and when to predict `0` to maximize F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:16.963537Z",
     "iopub.status.busy": "2023-02-08T17:34:16.962681Z",
     "iopub.status.idle": "2023-02-08T17:34:17.058758Z",
     "shell.execute_reply": "2023-02-08T17:34:17.057412Z",
     "shell.execute_reply.started": "2023-02-08T17:34:16.963481Z"
    }
   },
   "outputs": [],
   "source": [
    "# PUT TRUE LABELS INTO DATAFRAME WITH 18 COLUMNS\n",
    "true = oof.copy()\n",
    "for k in range(18):\n",
    "    # GET TRUE LABELS\n",
    "    tmp = targets.loc[targets.q == k+1].set_index('session').loc[ALL_USERS]\n",
    "    true[k] = tmp.correct.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:17.062356Z",
     "iopub.status.busy": "2023-02-08T17:34:17.061962Z",
     "iopub.status.idle": "2023-02-08T17:34:21.249674Z",
     "shell.execute_reply": "2023-02-08T17:34:21.248407Z",
     "shell.execute_reply.started": "2023-02-08T17:34:17.062314Z"
    }
   },
   "outputs": [],
   "source": [
    "# FIND BEST THRESHOLD TO CONVERT PROBS INTO 1s AND 0s\n",
    "scores = []; thresholds = []\n",
    "best_score = 0; best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0.4,0.81,0.01):\n",
    "    print(f'{threshold:.02f}, ',end='')\n",
    "    preds = (oof.values.reshape((-1))>threshold).astype('int')\n",
    "    m = f1_score(true.values.reshape((-1)), preds, average='macro')   \n",
    "    scores.append(m)\n",
    "    thresholds.append(threshold)\n",
    "    if m>best_score:\n",
    "        best_score = m\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:21.251719Z",
     "iopub.status.busy": "2023-02-08T17:34:21.251328Z",
     "iopub.status.idle": "2023-02-08T17:34:21.511216Z",
     "shell.execute_reply": "2023-02-08T17:34:21.510204Z",
     "shell.execute_reply.started": "2023-02-08T17:34:21.251684Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PLOT THRESHOLD VS. F1_SCORE\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(thresholds,scores,'-o',color='blue')\n",
    "plt.scatter([best_threshold], [best_score], color='blue', s=300, alpha=1)\n",
    "plt.xlabel('Threshold',size=14)\n",
    "plt.ylabel('Validation F1 Score',size=14)\n",
    "plt.title(f'Threshold vs. F1_Score with Best F1_Score = {best_score:.3f} at Best Threshold = {best_threshold:.3}',size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:21.513213Z",
     "iopub.status.busy": "2023-02-08T17:34:21.512633Z",
     "iopub.status.idle": "2023-02-08T17:34:21.721435Z",
     "shell.execute_reply": "2023-02-08T17:34:21.720081Z",
     "shell.execute_reply.started": "2023-02-08T17:34:21.513178Z"
    },
    "papermill": {
     "duration": 0.771134,
     "end_time": "2023-02-07T01:02:44.378465",
     "exception": false,
     "start_time": "2023-02-07T01:02:43.607331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('When using optimal threshold...')\n",
    "for k in range(18):\n",
    "        \n",
    "    # COMPUTE F1 SCORE PER QUESTION\n",
    "    m = f1_score(true[k].values, (oof[k].values>best_threshold).astype('int'), average='macro')\n",
    "    print(f'Q{k}: F1 =',m)\n",
    "    \n",
    "# COMPUTE F1 SCORE OVERALL\n",
    "m = f1_score(true.values.reshape((-1)), (oof.values.reshape((-1))>best_threshold).astype('int'), average='macro')\n",
    "print('==> Overall F1 =',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011075,
     "end_time": "2023-02-07T01:02:44.400918",
     "exception": false,
     "start_time": "2023-02-07T01:02:44.389843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:21.723302Z",
     "iopub.status.busy": "2023-02-08T17:34:21.722932Z",
     "iopub.status.idle": "2023-02-08T17:34:21.877575Z",
     "shell.execute_reply": "2023-02-08T17:34:21.876046Z",
     "shell.execute_reply.started": "2023-02-08T17:34:21.723272Z"
    },
    "papermill": {
     "duration": 0.052132,
     "end_time": "2023-02-07T01:02:44.464739",
     "exception": false,
     "start_time": "2023-02-07T01:02:44.412607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORT KAGGLE API\n",
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "# CLEAR MEMORY\n",
    "import gc\n",
    "del train, targets, df, oof, true\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:21.879865Z",
     "iopub.status.busy": "2023-02-08T17:34:21.878967Z",
     "iopub.status.idle": "2023-02-08T17:34:22.802272Z",
     "shell.execute_reply": "2023-02-08T17:34:22.80116Z",
     "shell.execute_reply.started": "2023-02-08T17:34:21.879826Z"
    },
    "papermill": {
     "duration": 1.002014,
     "end_time": "2023-02-07T01:02:45.47927",
     "exception": false,
     "start_time": "2023-02-07T01:02:44.477256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for (sample_submission, test) in iter_test:\n",
    "    \n",
    "    # FEATURE ENGINEER TEST DATA\n",
    "    df = feature_engineer(test)\n",
    "    \n",
    "    # INFER TEST DATA\n",
    "    grp = test.level_group.values[0]\n",
    "    a,b = limits[grp]\n",
    "    for t in range(a,b):\n",
    "        clf = models[f'{grp}_{t}']\n",
    "        p = clf.predict_proba(df[FEATURES].astype('float32'))[:,1]\n",
    "        mask = sample_submission.session_id.str.contains(f'q{t}')\n",
    "        sample_submission.loc[mask,'correct'] = int(p.item()>best_threshold)\n",
    "    \n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011427,
     "end_time": "2023-02-07T01:02:45.502331",
     "exception": false,
     "start_time": "2023-02-07T01:02:45.490904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:22.804278Z",
     "iopub.status.busy": "2023-02-08T17:34:22.803869Z",
     "iopub.status.idle": "2023-02-08T17:34:22.822354Z",
     "shell.execute_reply": "2023-02-08T17:34:22.821267Z",
     "shell.execute_reply.started": "2023-02-08T17:34:22.804243Z"
    },
    "papermill": {
     "duration": 0.027432,
     "end_time": "2023-02-07T01:02:45.541022",
     "exception": false,
     "start_time": "2023-02-07T01:02:45.51359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('submission.csv')\n",
    "print( df.shape )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T17:34:22.824242Z",
     "iopub.status.busy": "2023-02-08T17:34:22.823634Z",
     "iopub.status.idle": "2023-02-08T17:34:22.830441Z",
     "shell.execute_reply": "2023-02-08T17:34:22.829253Z",
     "shell.execute_reply.started": "2023-02-08T17:34:22.824195Z"
    },
    "papermill": {
     "duration": 0.020233,
     "end_time": "2023-02-07T01:02:45.57314",
     "exception": false,
     "start_time": "2023-02-07T01:02:45.552907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.correct.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
